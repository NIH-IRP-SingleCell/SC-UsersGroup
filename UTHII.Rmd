---title: "Under the Hood II - Pseudotemporal Ordering / Trajectory Inference"author: "The Single Cell Users Group"date: "15/04/2019"output: html_document---```{r setup, include=FALSE}knitr::opts_chunk$set(echo = FALSE)```# Pseudotemporal Ordering / Trajectory InferenceWe begin by setting some global constants.  We will work with dataset from the mouse cell atlas which is widely used in examples.  This input data is already in the form of count matrices and will be assumed to reside in the data subdirectory of the base_directory.  Since the datasets we are using are moderately large, we will be caching intermediate results; cached data will assumed to reside in the cache subdirectory of the base_directory.  This mark-down as well as a set of convenience functions needed by this mark-down will be assumed to reside in the R subdirectory of the base_directory.  Overall the file structure expected by this mark-down looks as follows:<base_directory> |                 +-- cache                 +-- classifer                 +-- data                 +-- output                 +-- RIn the following, we set the location of the base directory, source the R script containing the convenience functions and specify whether or not to force recalculation of intermediate results.*NOTE: These settings need to be modified for your personal implementation.*```{r}# Location base directorybase.dir <- "/Users/cordessf/UTHII"# Source the convenience functionssource(file = file.path(base.dir, "R/utilities.R"))# Force recalculation of intermediate results (working data)force.recalculation <- FALSE# # Force recalculation of intermediate results (batche effect data)force.batch.recalculation <- TRUE```## Read in Selected DataThe data is originates from the  paper by S. Lai et al (Cell Discovery 4(2018):34).  The raw sequencing data and digital gene expression (DGE) data are accessible through the Gene Expression Omnibus (GEO), accesssion code GSE92274.  In this mark down we use only the DGE data.We have added information about the data into a file called metadata.txt, which should be placed into the same directory as the data.  The full data from this paper contains human and zebrafish data.  Fo focus this analysis, we'll apply some selection criteria.  We'll choose mouse data that has not been pre-sorted (e.g. no ckit+ selection on the cells prior to single cell RNA-seq).  The data is in the format of a flat file (.txt) which contains the raw count matrix.  To begin we will construct Seurat objects.  Later we will convert them to monocle objects.  In the background some convenience functions that we provide do some of the work.```{r}murine.data <- acquire_raw_data(base.data.dir = file.path(base.dir, "data"),                                data.format = "txt",                                object.type = "Seurat",                                selection.criteria = c("species == \"mouse\"", "selection == \"None\""))```## Basic FilteringWe'll do some basic filtering to eliminate dead and poor quality cells.  Filter features that are not present in more than specified fraction of cells.  Filter cells that have more than specified percentage of mitochondrial reads or have number of reads below specified quantile in the distribution of reads by cell,```{r}murine.data <- basic.filtering(murine.data)```## Merge DataAt this point data from separate samples has not been merged.  Now we shall merge at the samples (without integration).  This process just keeps the features (genes) that are common to all the ```{r}merged.murine.data <- merge_sol(seurat_object_list = murine.data)```## Cluster the Merged Data```{r}clustered.merged.murine.data <- dimensionally_reduce_data(so = merged.murine.data,                                                          data_type = "Merged",                                                          output.dir = file.path(base.dir, "output"),                                                          plot_title = "Full")```## Batch Correction StrategiesFor the datasets used in this example, we do not have information on how the sequencing was done.  We have annotated with some phony batch numbers.  Since the datasets are large and computations are slow, we shall downsample the data.```{r}# Downsampledownsampled.murine.data <- merged.murine.data[,sample(1:ncol(merged.murine.data), size = 10000, replace = FALSE)]# Normalize the data between the cellsdownsampled.murine.data <- Seurat::NormalizeData(object = downsampled.murine.data)# Find variable featuresdownsampled.murine.data <- Seurat::FindVariableFeatures(object = downsampled.murine.data,                                                        mean.function = ExpMean,                                                        dispersion.function = LogVMR,                                                        x.low.cutoff = 0.0125,                                                        x.high.cutoff = 8,                                                        y.low.cutoff = 0.5,                                                        y.high.cutoff = 8,                                                        nfeatures = 1000)# Restrict genes to the most variabledownsampled.murine.data <- downsampled.murine.data[Seurat::VariableFeatures(downsampled.murine.data), ]# Scale Datadownsampled.murine.data <- Seurat::ScaleData(object = downsampled.murine.data,                                             vars.to.regress = c("nUMI", "fraction.mito"))clustered.downsampled.murine.data <- dimensionally_reduce_data(so = downsampled.murine.data,                                                               data_type = "Merged",                                                               output.dir = file.path(base.dir, "output"),                                                               plot_title = "Downsampled")```### RegressionOne of the oldest methods used for the mitigation of batch effects is regression.  Let's say we are interested in establishing whether there are any biologically real differences between the murine hematopoietic cells selected for by cKit positivity and the unselected cells, but samples have been processed in batches (which we in fact do not know, but have randomly assigned).  We can linear regression to eliminate the batch effects as follows```{r}# Assemble phenotypic data about the cells# ... Extract the metadata from the Seurat objectpD <- downsampled.murine.data@meta.data# Assemble expression dataeD <- GetAssayData(downsampled.murine.data, slot = "counts")# Create the model and null model matricesmod0 <- model.matrix(~1, data = pD)# Apply ComBat function to the data, using parametric empirical Bayesian adjustmentscombat_eD <- sva::ComBat(dat = as.matrix(eD),                         batch = factor(pD$phony.batch),                         mod = mod0,                         par.prior = TRUE,                         prior.plots = TRUE)# Trim extreme values and prepare to re-sparsifymax.out <- ceiling(max(eD) + 1)combat_eD[combat_eD < 1e-4] <- 0combat_eD[combat_eD > max.out] <- max.out# Replace data with batch-corrected dataregressed.downsampled.murine.data <- SetAssayData(object = downsampled.murine.data,                                                  slot = "counts",                                                  new.data = as(round(combat_eD, digits = 4), "dgCMatrix"),                                                  assay = "RNA")```### Plot Data with Batch Effects Regressed Out```{r}# if(calculate_it(force.recalculation = force.batch.recalculation, RData.file = regressed.downsampled.murine.Rdata)) {clustered.downsampled.murine.data <- dimensionally_reduce_data(so = regressed.downsampled.murine.data,                                                               data_type = "Merged",                                                               output.dir = file.path(base.dir, "output"),                                                               plot_title = "Regressed Downsampled")```### Mutual Nearest NeighborsAnother approach for batch correction is to use mutual nearest neighbors```{r}# Assemble phenotypic data about the cells# ... Extract the metadata from the Seurat objectpD <- downsampled.murine.data@meta.databatches <- levels(factor(pD$phony.batch))# Assemble expression dataeD <- GetAssayData(downsampled.murine.data, slot = "counts")# Construct list of expression matrices one for each batch levelcells.by.level <- list(); eD.by.level <- list()for(b in batches) {  cells.by.level[[b]] <- rownames(subset(x = pD, subset = phony.batch == b))  eD.by.level[[b]] <- as.matrix(eD[, cells.by.level[[b]]])}# Call the mutual nearest neighbors batch correction programmnn_eD <- scran::mnnCorrect(eD.by.level[[1]], eD.by.level[[2]], eD.by.level[[3]])# Combine the corrected matrices and return to original order of the cellsmnn_eD <- cbind(mnn_eD$corrected[[1]], mnn_eD$corrected[[2]], mnn_eD$corrected[[3]])colnames(mnn_eD) <- c(cells.by.level[[1]], cells.by.level[[2]], cells.by.level[[3]])mnn_eD <- mnn_eD[, colnames(eD)]# Re-sparsify the datamax.out <- ceiling(max(eD) + 1)mnn_eD[mnn_eD < 1e-4] <- 0mnn_eD[mnn_eD > max.out] <- max.out# Replace data with batch-corrected datamnn.murine.data <- Seurat::SubsetData(object = downsampled.murine.data, cells = colnames(mnn_eD))mnn.murine.data <- SetAssayData(object = mnn.murine.data,                                slot = "counts",                                new.data = as(round(mnn_eD, digits = 4), "dgCMatrix"),                                assay = "RNA")```## Plot the MNN batch-corrected data```{r}clustered.mnn.murine.data <- dimensionally_reduce_data(so = mnn.murine.data,                                                       data_type = "Merged",                                                       output.dir = file.path(base.dir, "output"),                                                       plot_title = "MNN Downsampled")```## Integrating the Data```{r}merged.murine.data <- Seurat::FindVariableFeatures(object = merged.murine.data,                                                   mean.function = Seurat::ExpMean,                                                   dispersion.function = Seurat::LogVMR,                                                   x.low.cutoff = 0.0125, x.high.cutoff = 3,                                                   y.cutoff = 0.5,                                                   do.plot = FALSE)# Split the data prior to integrationsplit.murine.data <- Seurat::SplitObject(object = merged.murine.data, split.by = "sample.name")murine.anchors <- Seurat::FindIntegrationAnchors(object.list = split.murine.data, dims = 1:30, verbose = TRUE)integrated.murine.data <- Seurat::IntegrateData(anchorset = murine.anchors, dims = 1:30, verbose = TRUE)Seurat::DefaultAssay(object = integrated.murine.data) <- "integrated"```## PlotPlot the integrated dataset```{r}clustered.integrated.murine.data <- dimensionally_reduce_data(so = integrated.murine.data,                                                              data_type = "Integrated",                                                              output.dir = file.path(base.dir, "output"),                                                              plot_title = "Partial")```## Classify clusters by cell type```{r}# Infer cell typecell_types <- scMCA(scdata = GetAssayData(clustered.merged.murine.data))# Assign inferred cell type back to the Seurat objectclassified.murine.data <- AddMetaData(object = clustered.merged.murine.data,                                      metadata = cell_types$scMCA,                                      col.name = "scMCA_cell_type")# Determine most prevalent cell type in each clusterfreq_type_by_cluster <- table(Idents(object = clustered.merged.murine.data), cell_types$scMCA)type_by_cluster <- colnames(data.matrix(freq_type_by_cluster))[apply(data.matrix(freq_type_by_cluster), 1, which.max)]num_clusters <- length(levels(Idents(clustered.merged.murine.data)))names(type_by_cluster) <- 0:(num_clusters - 1)classified.murine.data <- AddMetaData(object = clustered.merged.murine.data,                                      metadata = type_by_cluster[Idents(clustered.merged.murine.data)],                                      col.name = "cluster_cell_type")p <- Seurat::DimPlot(classified.murine.data, reduction = "umap", group.by = "cluster_cell_type")ggplot2::ggsave(filename = file.path(base.dir, "output/Merged Data with inferrred cell types.pdf"), plot = p)```These assignments of cell type are almost certainly not correct.  Partly this is due to the fact that we are assigning the entirely of cells in a cluster to one cell type and our clustering is too broad## Monocle AnalysisWe convert the data from Seurat objects to CellDataSets```{r}merged.murine.cds <- so_to_cds(classified.murine.data)```### Dimensionally reduceDimensionally reduce the CellDataSet```{r}# Estimate size factorsmerged.murine.cds <- BiocGenerics::estimateSizeFactors(merged.murine.cds)# Estimate dispersionsmerged.murine.cds <- BiocGenerics::estimateDispersions(merged.murine.cds)# Subset the dispersion table to identify the top varying genesdisp_table <- dispersionTable(merged.murine.cds)disp_table <- disp_table %>% dplyr::mutate(excess_disp = (dispersion_empirical - dispersion_fit) / dispersion_fit) %>% dplyr::arrange(dplyr::desc(excess_disp))top_subset_genes <- as.character(head(disp_table, 1000)$gene_id)merged.murine.cds <- monocle::setOrderingFilter(merged.murine.cds, top_subset_genes)merged.murine.cds <- monocle::preprocessCDS(merged.murine.cds, num_dim = 20)merged.murine.cds <- monocle::reduceDimension(merged.murine.cds,                                              reduction_method = "UMAP",                                              verbose = TRUE)k.nn <- 10*ceiling(sqrt(ncol(exprs(merged.murine.cds)))/10)merged.murine.cds <- monocle::clusterCells(merged.murine.cds,                                           k = k.nn,                                           method = 'louvain',                                           res =5e-3,                                           random_seed = 123L,                                           verbose = TRUE)p1 <- plot_cell_clusters(merged.murine.cds,                         color_by = "Cluster",                         cell_size = 0.5,                         show_group_id = FALSE)ggplot2::ggsave(filename = file.path(base.dir, "output/Clustered merged murine CDS.pdf"), plot = p1)```### Pseudotemporally order cellsVery basic pseudotemporal ordering of cells.  This is usually the departure point for studying the differential expression of genes that might regulate different developmental trajectories.  We will not take this very far.  In a separate Jupyter notebook we show how comparable analyses may be performed using scanpy and PAGA.```{r}pseudotemporally.ordered.murine.cds.data <- monocle::partitionCells(cds = merged.murine.cds)pseudotemporally.ordered.murine.cds.data <- learnGraph(pseudotemporally.ordered.murine.cds.data, RGE_method = 'SimplePPT')p <- plot_cell_trajectory(pseudotemporally.ordered.murine.cds.data,                          cell_size = 0.1,                          color_by = "Cluster")ggsave(filename = file.path(base.dir, "output/Pseudotemporally Ordered Clusters.pdf"))```