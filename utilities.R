# Load required biconductor and CRAN packagesrequire(BiocGenerics)# Enable only semi-serious parallel processing - only max of 2 coressuppressPackageStartupMessages(require("BiocParallel"))n.cores <- min(2, parallel::detectCores())BiocParallel::register(BiocParallel::MulticoreParam(n.cores))# Enable keeping only 1GB blocks of input in RAM - rest randomly accessible from file systemsuppressPackageStartupMessages(require("DelayedArray"))DelayedArray:::set_verbose_block_processing(TRUE)options(DelayedArray.auto.block.size = 1e9)# Load some other libraries required by monoclesuppressPackageStartupMessages(require("dplyr"))suppressPackageStartupMessages(require("garnett"))suppressPackageStartupMessages(require("ggplot2"))suppressPackageStartupMessages(require("ggrastr"))suppressPackageStartupMessages(require("igraph"))# Load monoclesuppressPackageStartupMessages(require("Matrix"))suppressPackageStartupMessages(require("monocle"))# Load dB's required for mouse annotationsuppressPackageStartupMessages(require("org.Mm.eg.db"))org_db <- org.Mm.eg.db# Load reticulatesuppressPackageStartupMessages(require("reticulate"))# Load scran (for MNN)suppressPackageStartupMessages(require("scran"))# Load scMCAsuppressPackageStartupMessages(require(scMCA))# Load SeuratsuppressPackageStartupMessages(require("Seurat"))# Load sva (for batch correction via combat)suppressPackageStartupMessages(require("sva"))suppressPackageStartupMessages(require("VGAM"))# Load required python modulespy_scrublet <- reticulate::import("louvain")# Define some convenience functions##################### acquire_raw_data ###################### Reads in all count matrices (assumed to be in compressed .gz or .zip) from a specified directory# into a list of Serurat or CellDataSet objects (as specified by the user)acquire_raw_data <- function(base.data.dir,                             data.format = c("10X", "txt"),                             object.type = c("Seurat", "monocle"),                             selection.criteria = character(0))  # Example of valid selection criteria (if vector of criteria is specified, then evaluates the logical "AND")  #  #   selection.criteria = c("species == \"mouse\""){  # Argument validation  data.format <- match.arg(data.format)  object.type <- match.arg(object.type)    if(grepl("10X", data.format, ignore.case = TRUE) && length(selection.criteria)) {    cat("[acquire_raw_data] Warning Subselection of 10X data not enabled in this version of scripts.")    selection.criteria <- character(0)  }    # Determine whether metadata file exists  if(file.exists(file.path(base.data.dir, "metadata.txt"))) {    metadata <- read_metadata(metadata.file = file.path(base.data.dir, "metadata.txt"),                              selection.criteria = selection.criteria)    print(metadata)  } else {    stop("[acquire_raw_data] Check that (required) metadata file exists and is placed in the same directory as data.")  }    # Ensure that the base data directory actually exists  if(!dir.exists(base.data.dir)) {    stop("[acquire_raw_data] base.data.dir", base.data.dir, "not found.")  }    # Determine the format of the data  if(grepl("10X", data.format, ignore.case = TRUE)) {    # Data is in 10X format - Get list of sub-directories containing the data    data.files <- sapply(system(paste('ls -d ', file.path(base.data.dir, '/*/')), intern = TRUE),                         function(s){tail(strsplit(s, '[/]')[[1]], 1)})  } else {    # Data is in canonical text format -  Obtain the list of data files    data.files <- metadata$sample.name  }    # Instantiate [monocle or Seurat] object list  object_list <- list()  for(file in data.files) {    origin <- strsplit(file, "[.]")[[1]][1]    cat("Obtaining data from", origin, " ... ")        # Read in the data    if(grepl("10X", data.format, ignore.case = TRUE)) {      # Data is in HD5 format, we'll use Seurat function to read it      data.dir <- file.path(base.data.dir, file, paste0('filtered_feature_bc_matrix'))            if(!dir.exists(data.dir)) {        compressed.data.dir <- file.path(base.data.dir, file, paste0(file, '_filtered_feature_bc_matrix.tar.gz'))        if(file.exists(compressed.data.dir)) {          # Uncompress and unarchive the count matrix - do this within the local directory          cwd <- getwd()          setwd(dir = file.path(base.data.dir, file))          system(paste0('tar -xvzf ', compressed.data.dir), wait = TRUE)          setwd(dir = cwd)        }      }            if(dir.exists(data.dir)) {        counts <- Read10X(data.dir = data.dir)      } else {        stop("[acquire_raw_data] No filtered feature count matrix found for ", file)      }          } else if(grepl("txt", data.format, ignore.case = TRUE)) {      # Data is in flat txt file format      if(grepl(".zip$", file, ignore.case = TRUE)) {        # Compression method is 'zip' rather than 'gzip', will need to convert        file_gz <- gsub(".zip$", ".gz", file)                # Convert to gz file and read in        system(paste("unzip -c", file.path(base.data.dir, file), "| gzip > ", file_gz), wait = TRUE)        dense.counts <- read.table(file = file.path(base.data.dir, file_gz), header = TRUE, sep = "", stringsAsFactors = FALSE)                # Delete the temporary gz file        system(paste("rm", file.path(base.data.dir, file_gz)))      } else {        dense.counts <- read.table(file = file.path(base.data.dir, file), header = TRUE, sep = "", stringsAsFactors = FALSE)      }            if(all(is.character(dense.counts[, 1]))) {        genes <- dense.counts[, 1]        dense.counts <- dense.counts[, -1]        rownames(dense.counts) <- genes      }      counts <- Seurat::as.sparse(dense.counts)    } else {      stop("[acquire_raw_data] Unrecognized data format ", data.format)    }        # Fix up cell and gene names    colnames(counts) <- gsub("_", "-", colnames(counts)); cells <- colnames(counts)    rownames(counts) <- gsub("_", "-", rownames(counts)); genes <- rownames(counts)        # Generate some phenotypic data    # ... fraction of mitochondrial reads    mito.genes <- grep(pattern = "^MT-", x = rownames(counts), ignore.case = TRUE, value = TRUE)    fraction.mito <- Matrix::colSums(counts[mito.genes, ])/Matrix::colSums(counts)        this.md <- data.frame(fraction.mito = fraction.mito)    # Determine whether additional metadata is available    if(!is.null(metadata)) {      for(m in names(metadata)) {        this.md <- data.frame(this.md, rep(metadata[file, m], ncol(counts)))      }      names(this.md) <- c("fraction.mito", names(metadata))    }        # Convert into Seurat or monocle object    if(grepl("seur", object.type, ignore.case = TRUE)) {      object_list[[origin]] <- Seurat::CreateSeuratObject(counts = counts, meta.data = this.md)    } else if(grepl("mono", object.type, ignore.case = TRUE)) {      # ... Assemble feature data      feature.data <- data.frame(gene_id = genes, gene_short_name = genes); rownames(feature.data) <- genes      fd <- new("AnnotatedDataFrame", data = feature.data)            # ... Assemble phenotypic data      pd <- new("AnnotatedDataFrame", data = this.md)            # ... Instantiate the CellDataSet      object_list[[origin]] <- monocle::newCellDataSet(cellData = counts,                                                       phenoData = pd,                                                       featureData = fd,                                                       expressionFamily = VGAM::negbinomial.size())    } else {      stop("[acquire_raw_mca_data] Profuse apologies - I don't yet know how to instantiate objects of type", object.type)    }    cat("Done.\n")  }    invisible(object_list)}#################### basic.filtering ####################basic.filtering <- function(sol,                            feature.sd = 2.5,                            max.fraction.mito = 0.05,                            percent.cells = 1){  for(n in names(sol)) {    cat("Filtering ", n, " ... ")    so <- sol[[n]]        # Get total number of cells    num_cells <- ncol(so)        # Filter features    min_cells <- percent.cells*num_cells/100    num_cells <- rowSums(GetAssayData(so) > 0)    so <- so[num_cells > min_cells, ]        # Filter percent mitochondria    so <- so[, so@meta.data$fraction.mito < max.fraction.mito]        # Filter cells    num_features <- colSums(GetAssayData(so))    min_features <- quantile(num_features, 1 - pnorm(feature.sd))    so <- so[, num_features > min_features]        sol[[n]] <- so    cat("Done.\n")  }    invisible(sol)}################# calculate_it #################calculate_it <- function(force.recalculation, RData.file){  calc_it <- force.recalculation || !file.exists(RData.file)  if(!calc_it) {    cat("Loading", RData.file, " ... ")    load(file = RData.file)    cat("Done.\n")  }    return(calc_it)}############################## dimensionally_reduce_data ##############################dimensionally_reduce_data <- function(so,                                      data_type = c("Merged", "Integrated"),                                      dim.reduc = 30L,                                      k = 1.0,                                      md = 0.001,                                      n.iter = 1,                                      prune.SNN = 1/15,                                      res = 0.5,                                      output.dir = "~/Downloads",                                      plot_title = ""){  # Sanity checks on anrguments  data_type <- match.arg(data_type)    if(data_type == "Integrated") {    # Scale Data    scaled_data <- Seurat::ScaleData(object = so,                                     vars.to.regress = c("nUMI", "fraction.mito"))  } else {    # Normalize the data between the cells    normalized_data <- Seurat::NormalizeData(object = so)        # Find variable features    normalized_data <- Seurat::FindVariableFeatures(object = normalized_data,                                                    mean.function = ExpMean,                                                    dispersion.function = LogVMR,                                                    x.low.cutoff = 0.0125,                                                    x.high.cutoff = 8,                                                    y.low.cutoff = 0.5,                                                    y.high.cutoff = 8)        # Scale Data    scaled_data <- Seurat::ScaleData(object = normalized_data,                                     vars.to.regress = c("nUMI", "fraction.mito"))  }    # Perform PCA  scaled_data <- Seurat::RunPCA(object = scaled_data,                                npcs = dim.reduc,                                verbose = TRUE,                                seed.use = 123)    # Dimensionally reduce via UMAP  scaled_data <- Seurat::RunUMAP(object = scaled_data, min.dist = md)    # Cluster the data  nn <- 10*k*round(sqrt(ncol(scaled_data))/10)  scaled_data <- Seurat::FindNeighbors(object = scaled_data, dims = 1:dim.reduc, k.param = nn)  scaled_data <- Seurat::FindClusters(object = scaled_data, resolution = res, n.iter = n.iter)    # Plot dimensional reduction grouped by "cluster ID"  p1_umap <- Seurat::DimPlot(scaled_data, reduction = "umap", group.by = "ident")    # Plot dimensional reduction grouped by "sample.name"  p2_umap <- Seurat::DimPlot(scaled_data, reduction = "umap", group.by = "clean.name")    # Plot dimensional reduction grouped by "treatment"  p3_umap <- Seurat::DimPlot(scaled_data, reduction = "umap", group.by = "selection")    # PDF  plot_title <- paste0(plot_title, " - ", data_type, " UMAP -- md = ", md, " nn = ", nn, " res = ", res, ".pdf")  pdf(file = file.path(output.dir, plot_title))  plot(p1_umap)  plot(p2_umap)  plot(p3_umap)  dev.off()    invisible(scaled_data)}####################### estimate_root_node #######################estimate_root_node <- function(cds,                               cell_phenotype,                               root_type){  # Note this function is lifted from Trapnell's tutorial.  One very interesting fact to keep in mind:  #  #      pr_graph_cell_proj_closest_vertex is just a matrix with a single column that stores for each cell,  #                                        the ID of the principal graph node it's closest to.  #  # This is handy for computing statistics (e.g. with dplyr) about the principal graph nodes and which  # cells of what type map to them.   cell_ids <- which(pData(cds)[, cell_phenotype] == root_type)    closest_vertex <-    cds@auxOrderingData[[cds@rge_method]]$pr_graph_cell_proj_closest_vertex  closest_vertex <- as.matrix(closest_vertex[colnames(cds), ])  root_pr_nodes <-    V(cds@minSpanningTree)$name[as.numeric(names                                           (which.max(table(closest_vertex[cell_ids,]))))]    root_pr_nodes}############## merge_sol ############### Merges a list of Seurat objects into a single Seurat objectmerge_sol <- function(seurat_object_list,                      project_name = "Mouse HSPCs"){  for(n in names(seurat_object_list)) {    cat("Processing library: ", n, " ... ")        # Rename the cells    seurat_object_list[[n]] <- Seurat::RenameCells(object = seurat_object_list[[n]], add.cell.id = n)        if(n == names(seurat_object_list)[1]) {      so_merged <- seurat_object_list[[1]]    } else {      so_merged <- merge(x = so_merged, y = seurat_object_list[[n]], project = project_name)    }        cat("Done.\n")  }    invisible(so_merged)}################## read_metadata ##################read_metadata <- function(metadata.file, selection.criteria = character(0)){  metadata <- read.table(file = metadata.file,                         header = TRUE, sep = "\t", stringsAsFactors = TRUE)    if(!any(grepl("sample.name", names(metadata), ignore.case = FALSE))) {    stop("[read_metadata] Metadata is missing column \"sample.data\".")  }    metadata.cols <- names(metadata)  clean.name <- gsub(".txt|.txt.gz|.txt.zip", "", metadata$sample.name)  metadata <- data.frame(clean.name = clean.name, metadata)  names(metadata) <- c("clean.name", metadata.cols)  rownames(metadata) <- metadata$sample.name    if(length(selection.criteria)) {    metadata <- eval(parse(text = paste("subset(metadata, subset =", paste0(selection.criteria, collapse = " & "), ")")))  }  invisible(metadata)}############## so_to_cds ##############so_to_cds <- function(so){  # ... Assemble feature data  genes <- rownames(so)  feature.data <- data.frame(gene_id = genes, gene_short_name = genes); rownames(feature.data) <- genes  fd <- new("AnnotatedDataFrame", data = feature.data)    # ... Assemble phenotypic data  pd <- new("AnnotatedDataFrame", data = so@meta.data)    # ... Instantiate the CellDataSet  cds <- monocle::newCellDataSet(cellData = GetAssayData(so),                                 phenoData = pd,                                 featureData = fd,                                 expressionFamily = VGAM::negbinomial.size())  invisible(cds)}